---
title: "R Notebook"
output: html_notebook
---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)

library(tidyverse)

set.seed(19)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set),  size = nrow(titanic_set)*0.2)

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```
# question 1

```{r}
titanic_set <- titanic_set %>% 
  select(-c(name, passenger_id, fare, cabin, X1, ticket)) %>% 
  drop_na(survived) %>% 
  mutate(pclass = as.factor(pclass)) %>% 
  mutate(sex = as.factor(sex)) %>% 
  mutate(age_status = as.factor(if_else(age <= 16, "child", "adult"))) %>% 
  mutate(survived = as.factor(survived)) %>% 
  mutate(embarked = as.factor(embarked)) %>% 
  na.omit()
```

# question 2  
## Have a look at your data and create some plots to ensure you know what youâ€™re working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.

```{r}
library(GGally)
ggpairs(titanic_set)
```
```{r}
titanic_set %>% 
  ggplot()+
  aes(x = sex, y = survived, fill = survived)+
  geom_col()
```
```{r}
titanic_set %>% 
  ggplot()+
  aes(x = age_status, y = survived, fill = survived)+
  geom_col()
```
```{r}
titanic_set %>% 
  ggplot()+
  aes(x = pclass, y = survived, fill = survived)+
  geom_col()
```

Variables likely to predict if someone was going to die are age, sex, and class. If graphed on their own, they are very skewed towards adult, male, and 3rd class. However, when taken as a proportion, it seems that a higher proportion per group were likely to survived based on being a child, female, and first class.

# question 3

## Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced.

### testing set
```{r}
titanic_test  <- slice(titanic_set, shuffle_index)

nrow(titanic_test)
```

### training set

```{r}
titanic_train <- slice(titanic_set,  -shuffle_index)

nrow(titanic_train)
```

```{r}
titanic_test %>%
  tabyl(survived)
```

```{r}
titanic_train %>% 
  tabyl(survived)
```

## question 4

### Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
titanic_fit <- rpart(
  formula = survived ~ ., 
  data = titanic_train, 
  method = 'class'
)

rpart.plot(titanic_fit, yesno = 2, fallen.leaves = TRUE, faclen = 6, digits = 4)
```
## question 5. Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.

### answer - it seems to confirm that age and sex and class were likely predictors.

## question 6

### Test and add your predicitons to your data. Create a confusion matrix. Write down in detial what this tells you for this specific dataset.

```{r}
library(modelr)

titanic_test_pred <- titanic_test %>%
  add_predictions(titanic_fit, type = 'class')
```

```{r}
rpart.predict(titanic_fit, newdata = titanic_test_pred[1:3,], rules=TRUE)
```
```{r}
library(yardstick)

conf_mat <- titanic_test_pred %>%
              conf_mat(truth = survived, estimate = pred)

conf_mat
```

```{r}
library(caret)

confusionMatrix(titanic_test_pred$pred, titanic_test_pred$survived) 
```



